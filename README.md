# üìò Books Scraper

Este projeto √© um web scraper desenvolvido em Python que utiliza Selenium para extrair informa√ß√µes de livros do site [books.toscrape.com](http://books.toscrape.com/). Os dados coletados s√£o exibidos em uma aplica√ß√£o web interativa criada com Streamlit, permitindo a filtragem e o download dos dados em formato CSV.

## Funcionalidades

- Coleta de dados de livros, incluindo t√≠tulo, UPC, pre√ßo, disponibilidade, n√∫mero de reviews, avalia√ß√£o e URL.
- Navega√ß√£o autom√°tica por todas as p√°ginas do cat√°logo de livros.
- Interface web interativa com Streamlit para visualiza√ß√£o e filtragem dos dados.
- Filtragem de livros por t√≠tulo.
- Download dos dados coletados em formato CSV.

## Tecnologias Utilizadas

- Python
- Selenium (para web scraping)
- Streamlit (para a interface web)
- Pandas (para manipula√ß√£o de dados)
- WebDriver Manager (para gerenciamento autom√°tico do ChromeDriver)

## Como executar

### 1. Pr√©-requisitos

- Python 3.7 ou superior.
- Google Chrome instalado. (O WebDriverManager cuidar√° da instala√ß√£o do ChromeDriver correspondente).

### 2. Instala√ß√£o

Primeiro, obtenha os arquivos do projeto. Voc√™ pode clonar o reposit√≥rio se tiver Git instalado:
```bash
git clone <url-do-repositorio>
cd <nome-do-repositorio>
```
Ou baixe os arquivos `.zip` e extraia-os.

Crie um ambiente virtual (altamente recomendado para isolar as depend√™ncias do projeto):
```bash
python -m venv venv
```

Ative o ambiente virtual:

- No Windows:
  ```bash
  .\venv\Scripts\activate
  ```
- No macOS/Linux:
  ```bash
  source venv/bin/activate
  ```

Com o ambiente virtual ativado, instale as depend√™ncias listadas no arquivo `requirements.txt`:
```bash
pip install -r requirements.txt
```

### 3. Executando a Aplica√ß√£o

Para iniciar a aplica√ß√£o Streamlit, execute o seguinte comando no terminal, na pasta raiz do projeto:
```bash
streamlit run main.py
```

A aplica√ß√£o ser√° aberta automaticamente no seu navegador padr√£o. Clique no bot√£o "üöÄ Iniciar raspagem" para come√ßar o processo de coleta de dados. Ap√≥s a conclus√£o, os livros ser√£o exibidos em uma tabela, onde voc√™ poder√° filtr√°-los por t√≠tulo e realizar o download dos dados em formato CSV.

## Estrutura do Projeto

- `main.py`: Cont√©m o c√≥digo da aplica√ß√£o Streamlit, respons√°vel pela interface do usu√°rio e l√≥gica de intera√ß√£o.
- `scraper.py`: M√≥dulo respons√°vel pela l√≥gica de raspagem de dados (web scraping) utilizando Selenium.
- `requirements.txt`: Lista todas as depend√™ncias Python necess√°rias para o projeto.
- `.gitignore`: Especifica arquivos e pastas que devem ser ignorados pelo Git.
- `books_scraper.log`: Arquivo de log gerado pela execu√ß√£o do scraper (configurado em `scraper.py`). Recomenda-se adicionar este arquivo ao `.gitignore`.
- `README.md`: Este arquivo, fornecendo informa√ß√µes sobre o projeto.

## Licen√ßa

Este projeto √© distribu√≠do sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes (se aplic√°vel, ou defina uma licen√ßa).
(Nota: Adicionar um arquivo LICENSE se desejar formalizar a licen√ßa)
```
